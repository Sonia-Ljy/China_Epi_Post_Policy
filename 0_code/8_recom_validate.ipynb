{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_pp_loc(mut):\n",
    "    if \"del\" in mut or \"ins\" in mut:\n",
    "        loc = int(mut.split(\"_\")[1][1:-3])\n",
    "    elif \"stop\" in mut:\n",
    "        loc = int(mut.split(\"_\")[1][1:-4])\n",
    "    else:\n",
    "        loc = int(mut.split(\"_\")[1][1:-1])\n",
    "    return loc\n",
    "\n",
    "\n",
    "def get_prim_pp(first_m):\n",
    "    prim_pp = first_m.split(\"_\")[1][0]\n",
    "    return prim_pp\n",
    "\n",
    "\n",
    "def trans_del_ins(first_m,pp,prim_pp,loc):\n",
    "    import re\n",
    "    if pp == \"S\":\n",
    "        new_pp = \"Spike_\"\n",
    "    elif pp in [\"ORF3\",\"ORF6\",\"ORF7\",\"ORF8\",\"ORF10\",\"ORF3a\",\"ORF6a\",\"ORF8a\",\"ORF10a\",\"ORF3b\",\"ORF6b\",\"ORF8b\",\"ORF10b\"]:\n",
    "        new_pp = \"NS\"+re.findall(r\"\\d+\\.?\\d*\",pp)[0]+\"_\"\n",
    "    elif pp == \"ORF7a\":\n",
    "        new_pp = \"NS7a_\"\n",
    "    elif pp == \"ORF7b\":\n",
    "        new_pp = \"NS7b_\"\n",
    "    else:\n",
    "        new_pp = pp+\"_\"\n",
    "        \n",
    "    if first_m[-1] == \"-\":\n",
    "        second_m = new_pp+prim_pp+loc+\"del\"\n",
    "    elif first_m[-1] == \"*\":\n",
    "        second_m = new_pp+prim_pp+loc+\"stop\"\n",
    "    else:\n",
    "        second_m = new_pp+prim_pp+loc+first_m.split(\"_\")[1][-1]\n",
    "    return second_m\n",
    "\n",
    "def regular_mut(mut_list):\n",
    "    if \"NS6_D61L\" in mut_list:\n",
    "        mut_list.remove(\"NS6_D61L\")\n",
    "    if \"Spike_R158G\" in mut_list:\n",
    "        mut_list.remove(\"Spike_R158G\")\n",
    "        mut_list.append(\"Spike_R158del\")\n",
    "    if \"Spike_E156del\" in mut_list:\n",
    "        mut_list.remove(\"Spike_E156del\")\n",
    "        mut_list.append(\"Spike_E156G\")\n",
    "    if \"Spike_L242del\" in mut_list:\n",
    "        mut_list.remove(\"Spike_L242del\")\n",
    "        mut_list.append(\"Spike_L244del\")\n",
    "    if \"NS7b_F13del\" in mut_list:\n",
    "        mut_list.remove(\"NS7b_F13del\")\n",
    "    if \"NS8_D119del\" in mut_list:\n",
    "        mut_list.remove(\"NS8_D119del\")\n",
    "    if \"NS8_F120del\" in mut_list:\n",
    "        mut_list.remove(\"NS8_F120del\")\n",
    "    if \"NS8_T87I\" in mut_list:\n",
    "        mut_list.remove(\"NS8_T87I\")\n",
    "    if \"NS8_D107E\" in mut_list:\n",
    "        mut_list.remove(\"NS8_D107E\")\n",
    "    if \"NS8_I121L\" in mut_list:\n",
    "        mut_list.remove(\"NS8_I121L\")\n",
    "    if \"NS8_F120V\" in mut_list:\n",
    "        mut_list.remove(\"NS8_F120V\")\n",
    "    if \"NS8_L118V\" in mut_list:\n",
    "        mut_list.remove(\"NS8_L118V\")\n",
    "    if \"NS8_I121del\" in mut_list:\n",
    "        mut_list.remove(\"NS8_I121del\")\n",
    "    if \"NS8_F120L\" in mut_list:\n",
    "        mut_list.remove(\"NS8_F120L\")\n",
    "        \n",
    "    return mut_list\n",
    "\n",
    "\n",
    "def sort_epi_mutation(epiV):\n",
    "    genome_proteim = [\"NSP1\",\"NSP2\",\"NSP3\",\"NSP4\",\"NSP5\",\"NSP6\",\"NSP7\",\"NSP8\",\"NSP9\",\"NSP10\",\"NSP12\",\"NSP13\",\"NSP14\",\"NSP15\",\"NSP16\",\"Spike\",\"NS3\",\"E\",\"M\",\"NS6\",\"NS7\",\"NS8\",\"N\",\"NS10\"]\n",
    "    sort_epiV = []\n",
    "    for pp in genome_proteim:\n",
    "        temp_mut = []\n",
    "        for mut in epiV:\n",
    "            pp_epi = mut.split(\"_\")[0]\n",
    "            if pp_epi == pp:\n",
    "                temp_mut.append(mut)\n",
    "            else:\n",
    "                continue\n",
    "        if len(temp_mut) >= 1:\n",
    "            mut_loc = {}\n",
    "            for n in temp_mut:\n",
    "                if \"del\" in n:\n",
    "                    loc = int(n.split(\"_\")[1][1:-3])\n",
    "                elif \"stop\" in n:\n",
    "                    loc = int(n.split(\"_\")[1][1:-4])\n",
    "                elif \"ins\" in n:\n",
    "                    loc = int(re.findall(\"\\d+\",n.split(\"_\")[1])[0])\n",
    "                else:\n",
    "                    loc = int(n.split(\"_\")[1][1:-1])\n",
    "                mut_loc[n] = loc\n",
    "            mut_loc_sorted = sorted(mut_loc.items(), key=lambda x: x[1], reverse=False)\n",
    "            mut_sort = [k[0] for k in mut_loc_sorted]\n",
    "            sort_epiV.extend(mut_sort)\n",
    "        else:\n",
    "            continue\n",
    "    return sort_epiV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "# 提取被nextclade判定为重组的序列\n",
    "next_recom_mutation = {}\n",
    "next_recom = []\n",
    "with open(\"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/nextclade.tsv\") as f:\n",
    "    next(f)\n",
    "    for row in f.readlines():\n",
    "        if row.split(\"\\t\")[2] == \"recombinant\":\n",
    "            info = (row.strip().split(\"\\t\"))\n",
    "            epi = info[1]\n",
    "            next_recom.append(epi)\n",
    "            mut_info = info[29].split(\",\")\n",
    "            del_info = info[30].split(\",\")\n",
    "            mut_info.extend(del_info)\n",
    "            next_recom_mutation[epi] = mut_info\n",
    "\n",
    "print(len(next_recom)) #105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRPATH = \"/home/soniali/Desktop/02_china_recom_renew/3_recom/\"\n",
    "with open(\"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/nextclade.aligned.fasta\",\"r\") as f:\n",
    "    for record in SeqIO.parse(f,\"fasta\"):\n",
    "        if record.id in next_recom:\n",
    "            with open(DIRPATH+\"aligned_china_next_recom_105.fasta\",\"a+\") as h:\n",
    "                h.write(\">\"+str(record.id)+\"\\n\")\n",
    "                h.write(str(record.seq)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = \"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/Qualified_china_meta_merged.csv\"\n",
    "df_meta = pd.read_csv(meta_file) \n",
    "df_meta2 = df_meta[df_meta[\"Accession_ID\"].isin(next_recom)]\n",
    "df_meta2.to_csv(\"/home/soniali/Desktop/02_china_recom_renew/3_recom/\"+\"meta_105.csv\",index=None,sep = \",\")\n",
    "\n",
    "seq_id_fas = {}\n",
    "with open(DIRPATH+\"aligned_china_next_recom_105.fasta\",\"r\") as f:\n",
    "    for record in SeqIO.parse(f,\"fasta\"):\n",
    "        seq_id_fas[str(record.id)] = str(record.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行9_china_select.py文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据GISAID获取的全球meta文件中所有序列的谱系及氨基酸变异信息，计算各谱系的特征变异，以10%或75%为阈值\n",
    "DIRPATH = '/home/soniali/Desktop/02_china_recom_renew/3_recom/'\n",
    "variant_surveillance_path = DIRPATH + 'metadata_china.tsv'\n",
    "# lineage_10_path = DIRPATH + 'lineagesFM/lineage_10_china.txt'\n",
    "lineage_75_path = DIRPATH + 'lineagesFM/lineage_75_china.txt'\n",
    "mutation_num_path = DIRPATH + 'lineagesFM/mutation_num_china.txt'\n",
    "output_file = DIRPATH + 'putative_recombination.csv'\n",
    "\n",
    "col_names = ['sample_id','lineage_X', 'lineage_Y', \\\n",
    "        'mutation_pattern', \"more_mut\",\"raw_p_value\",\"adjusted_p_value\",\"X_mutations\", \"Y_mutations\", \"shared_mutations\", \"denovo_mutations\"]\n",
    "with open(output_file, \"w\") as file_epi:\n",
    "    for c in col_names[0:-1]:\n",
    "        file_epi.write(c + \",\")\n",
    "    file_epi.write(col_names[-1] + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = []\n",
    "lineages = {}\n",
    "with open(variant_surveillance_path,\"r\") as f:\n",
    "    next(f)\n",
    "    num = 0\n",
    "    for row in f.readlines():\n",
    "        num+=1\n",
    "        l = row.strip().split(\",\")[4]\n",
    "        if l not in lineages:\n",
    "            lineages[l] = {'count': 1, 'mutations': {}}\n",
    "        else:\n",
    "            lineages[l]['count'] += 1\n",
    "        \n",
    "        substitutions = row.strip().split(\",\")[5:][1:-1]\n",
    "        substitutions.append(row.strip().split(\",\")[5:][0].split('\"')[-1])\n",
    "        substitutions.append(row.strip().split(\",\")[5:][-1].split('\"')[0])\n",
    "        for s in substitutions:\n",
    "            if 'ins' not in s and s != '':\n",
    "                mutations.append(s)\n",
    "                lineages[l]['mutations'][s] = lineages[l]['mutations'].get(s, 0) + 1\n",
    "\n",
    "mutations = list(set(mutations))\n",
    "with open(mutation_num_path, 'w') as f:\n",
    "    f.write('Num'+'\\n')\n",
    "    f.write(str(len(mutations))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lineages = dict(sorted(lineages.items(), key=lambda x: x[0]))\n",
    "defining_SNPs_75 = {}\n",
    "# defining_SNPs_10 = {}\n",
    "for l in lineages:\n",
    "    if l != 'None' and l != 'XA' :\n",
    "        for m in lineages[l]['mutations']:\n",
    "            if lineages[l]['mutations'][m] / lineages[l]['count'] > 0.1:\n",
    "                # defining_SNPs_10.setdefault(l, []).append(m)\n",
    "                if l not in defining_SNPs_75:\n",
    "                    defining_SNPs_75[l] = []\n",
    "            if lineages[l]['mutations'][m] / lineages[l]['count'] > 0.75:\n",
    "                defining_SNPs_75[l].append(m)\n",
    "\n",
    "# with open(lineage_10_path, 'w') as f:\n",
    "#     for l in defining_SNPs_10:\n",
    "#         f.write(l + ',' + str(lineages[l]['count']) + ',' + ','.join(defining_SNPs_10[l]) + '\\n')\n",
    "\n",
    "with open(lineage_75_path, 'w') as f:\n",
    "    for l in defining_SNPs_75:\n",
    "        f.write(l + ',' + str(lineages[l]['count']) + ',' + ','.join(defining_SNPs_75[l]) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_seq = {}\n",
    "with open(variant_surveillance_path,\"r\") as f:\n",
    "    next(f)\n",
    "    for row in f.readlines():\n",
    "        epi = row.strip().split(\",\")[0]\n",
    "        if {epi} - set(next_recom) == set():\n",
    "            substitutions = row.strip().split(\",\")[5:][1:-1]\n",
    "            substitutions.append(row.strip().split(\",\")[5:][0].split('\"')[-1])\n",
    "            substitutions.append(row.strip().split(\",\")[5:][-1].split('\"')[0])\n",
    "            query_seq[epi] = substitutions\n",
    "\n",
    "len(query_seq) #77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/soniali/Desktop/02_china_recom_renew/3_recom/SARS_CoV_2_detail.csv\")\n",
    "num = 0\n",
    "for epi in next_recom:\n",
    "    if epi not in query_seq.keys():\n",
    "        num+=1\n",
    "        mut_info  = next_recom_mutation[epi]\n",
    "        mut_list = []\n",
    "        for mut in mut_info:\n",
    "            first_m = mut.replace(\":\",\"_\")\n",
    "            pp = first_m.split(\"_\")[0]\n",
    "            prim_pp = get_prim_pp(first_m)\n",
    "            if pp == \"S\":\n",
    "                loc = str(get_pp_loc(first_m))\n",
    "                second_m = trans_del_ins(first_m,pp,prim_pp,loc)\n",
    "                mut_list.append(second_m)\n",
    "            elif pp in [\"E\",\"M\",\"ORF3\",\"ORF6\",\"ORF7\",\"ORF8\",\"N\",\"ORF10\",\"ORF3a\",\"ORF6a\",\"ORF7a\",\"ORF8a\",\"ORF10a\",\"ORF3b\",\"ORF6b\",\"ORF7b\",\"ORF8b\",\"ORF10b\"]:\n",
    "                loc = str(get_pp_loc(first_m))\n",
    "                second_m = trans_del_ins(first_m,pp,prim_pp,loc)\n",
    "                mut_list.append(second_m)\n",
    "            elif pp == \"ORF1a\":\n",
    "                df1 = df[df[\"gene_full\"] == pp]\n",
    "                df2 = df1[df1[\"peptidePos\"] == get_pp_loc(first_m)]\n",
    "                prim_pp = get_prim_pp(first_m)\n",
    "                df3 = df2[df2[\"aa\"] == prim_pp]\n",
    "                if len(set(df3[\"product\"].tolist())) == 1:\n",
    "                    new_pp = df3[\"product\"].tolist()[0]\n",
    "                    new_loc = str(df3[\"aaPos\"].tolist()[0])\n",
    "                    second_m = trans_del_ins(first_m,new_pp,prim_pp,new_loc)\n",
    "                    # print(mut,\"     \",second_m)\n",
    "                    mut_list.append(second_m)\n",
    "                    # epi_mut_list[epi].extend(mut_list)\n",
    "                else:\n",
    "                    print(epi,first_m)\n",
    "            elif pp == \"ORF1b\":\n",
    "                df1 = df[df[\"gene_full\"] == pp]\n",
    "                df2 = df1[df1[\"nextclade_aaPos\"] == get_pp_loc(first_m)]\n",
    "                prim_pp = get_prim_pp(first_m)\n",
    "                df3 = df2[df2[\"aa\"] == prim_pp]\n",
    "                if len(set(df3[\"product\"].tolist())) == 1:\n",
    "                    new_pp = df3[\"product\"].tolist()[0]\n",
    "                    new_loc = str(df3[\"aaPos\"].tolist()[0])\n",
    "                    second_m = trans_del_ins(first_m,new_pp,prim_pp,new_loc)\n",
    "                    mut_list.append(second_m)\n",
    "                else:\n",
    "                    print(epi,first_m)\n",
    "\n",
    "        query_seq[epi] = regular_mut(mut_list)\n",
    "        \n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from scipy.stats import hypergeom\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_file = \"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/Qualified_china_meta_merged.csv\"\n",
    "df_china_meta = pd.read_csv(meta_file) \n",
    "df_china_meta = df_china_meta[~df_china_meta[\"Accession_ID\"].isin(next_recom)]\n",
    "df_china_meta['date'] = pd.to_datetime(df_china_meta['Sample_Collection_Date']) # date转为时间格式\n",
    "element_counts = Counter(df_china_meta[\"Lineage\"].tolist())\n",
    "element_counts_dict = dict(element_counts)\n",
    "element_counts_dict_sort = dict(sorted(element_counts_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next_recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lineage_v = defining_SNPs_75\n",
    "feature_mutations = mutations\n",
    "mutaions_num = int(len(mutations))\n",
    "len_UXY = 4\n",
    "calculate_num = 0\n",
    "for epi in next_recom:\n",
    "    calculate_num+=1\n",
    "    epiV = query_seq[epi]\n",
    "    epi_feat = len(set(epiV) & set(feature_mutations))\n",
    "    # P-value for Non-recombination\n",
    "    epi_record = {}\n",
    "    aftertime_lin = []\n",
    "    for lin_A in Lineage_v:\n",
    "        aftertime_lin.append(lin_A)\n",
    "        all_AA = len(Lineage_v[lin_A]) \n",
    "        all_AA_epi = len(set(Lineage_v[lin_A]) & set(epiV))\n",
    "        pVal = hypergeom.sf(all_AA_epi - 1, mutaions_num, all_AA, epi_feat)\n",
    "        epi_record[str(lin_A) + \"_\" + str(lin_A)] = pVal\n",
    "\n",
    "    # the least p-value for the Non-recombinant\n",
    "    min_AA = min(epi_record, key = epi_record.get)\n",
    "    A_already = []\n",
    "    for A in aftertime_lin:\n",
    "        A_already.append(A)\n",
    "        A_epi = set(Lineage_v[A]) & set(epiV)\n",
    "        if len(A_epi) < len_UXY:\n",
    "            continue\n",
    "        else:\n",
    "            afterA_linB = set(aftertime_lin) - set(A_already)\n",
    "            for B in afterA_linB:\n",
    "                B_epi = set(Lineage_v[B]) & set(epiV)\n",
    "                if len(B_epi) < len_UXY:\n",
    "                    continue\n",
    "                else:\n",
    "                    unique_A = A_epi - B_epi\n",
    "                    unique_B = B_epi - A_epi\n",
    "                    if len(unique_A) < len_UXY or len(unique_B) < len_UXY:\n",
    "                        continue\n",
    "                    else:\n",
    "                        all_AB = len(set(Lineage_v[A]) | set(Lineage_v[B]))  \n",
    "                        all_AB_epi = len(set(set(Lineage_v[A]) | set(Lineage_v[B])) & set(epiV)) \n",
    "                        pVal = hypergeom.sf(all_AB_epi - 1, mutaions_num, all_AB, epi_feat)\n",
    "                        epi_record[str(A) + \"_\" + str(B)] = pVal\n",
    "\n",
    "    raw_pvals = list(epi_record.values())\n",
    "    rejected, p_adjusted, _, alpha_corrected = multipletests(raw_pvals, alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "\n",
    "    lin_adjP = {}\n",
    "    for p in range(len(p_adjusted)):\n",
    "        lin_pair = list(epi_record.keys())[p]\n",
    "        lin_adjP[lin_pair] = p_adjusted[p]\n",
    "    \n",
    "    # 判断亲本谱系存在\n",
    "    sorted_dict_by_value = dict(sorted(lin_adjP.items(), key=lambda item: item[1]))\n",
    "    lin_count = {}\n",
    "    for pair in sorted_dict_by_value:\n",
    "        a_lin, b_lin = pair.split(\"_\")[0], pair.split(\"_\")[1]\n",
    "        if a_lin != b_lin:\n",
    "            a,b = pair.split(\"_\")[0], pair.split(\"_\")[1]\n",
    "            if (a in element_counts_dict_sort) == True and (b in element_counts_dict_sort) == True:\n",
    "                lin_count[pair] = [element_counts_dict_sort[a],element_counts_dict_sort[b]]\n",
    "\n",
    "    if len(lin_count) >= 1:\n",
    "        raw_ab = 0\n",
    "        for ab in lin_count:\n",
    "            if sum(lin_count[ab]) >= raw_ab:\n",
    "                temp_ab = ab\n",
    "                raw_ab = sum(lin_count[ab])\n",
    "\n",
    "        min_adjp_pair = temp_ab\n",
    "        \n",
    "        if min_adjp_pair == min_AA or lin_adjP[min_adjp_pair] >= 0.05: \n",
    "            continue\n",
    "        else:\n",
    "            # print(epi,\"   \",min_adjp_pair,\"    \",min_AA)\n",
    "            lin_A_draw, lin_B_draw = min_adjp_pair.split(\"_\")[0],min_adjp_pair.split(\"_\")[1]\n",
    "\n",
    "            feature_SNPA = Lineage_v[lin_A_draw]\n",
    "            feature_SNPB = Lineage_v[lin_B_draw]\n",
    "            A_B_shared = set(feature_SNPA) & set(feature_SNPB)\n",
    "            UA_mutate = (set(feature_SNPA) & set(epiV)) - set(A_B_shared)\n",
    "            UB_mutate = (set(feature_SNPB) & set(epiV)) - set(A_B_shared)\n",
    "            sample_special = set(epiV) - (set(feature_SNPA) | set(feature_SNPB))\n",
    "\n",
    "            UA_mutate_unique = []\n",
    "            UB_mutate_unique = []\n",
    "            shared_mut = []\n",
    "            denovo_mut = []\n",
    "\n",
    "            lin_record = \"\"\n",
    "            epiV = sort_epi_mutation(epiV)\n",
    "            for j in epiV:\n",
    "                if j in A_B_shared:\n",
    "                    shared_mut.append(j)\n",
    "                elif j in UA_mutate:\n",
    "                    UA_mutate_unique.append(j)\n",
    "                    lin_record = lin_record + \"X\"\n",
    "                elif j in UB_mutate:\n",
    "                    UB_mutate_unique.append(j)\n",
    "                    lin_record = lin_record + \"Y\"\n",
    "                elif j in sample_special:\n",
    "                    denovo_mut.append(j)\n",
    "            \n",
    "            moremut = set(UA_mutate_unique + UB_mutate_unique) - set(Lineage_v[min_AA.split(\"_\")[0]])\n",
    "            # print(\"------------------------------------\")\n",
    "\n",
    "            if moremut == set():\n",
    "                continue\n",
    "            else:\n",
    "                with open(output_file, \"a+\") as file_epi:\n",
    "                    file_epi.write(epi + \",\" +lin_A_draw + \",\" + lin_B_draw + \",\" + lin_record +\",\"+\\\n",
    "                        str(epi_record[min_adjp_pair])+\",\"+str(lin_adjP[min_adjp_pair])+\",\"+\"/\".join(UA_mutate_unique) + \",\" + \"/\".join(UB_mutate_unique) +\\\n",
    "                            \",\" + \"/\".join(shared_mut) + \",\" + \"/\".join(denovo_mut) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察\"putative_recombination.csv\"结果\n",
    "putative_recom = [\"EPI_ISL_18289734\",\"EPI_ISL_18105656\",\"EPI_ISL_18289815\",\"EPI_ISL_18284946\",\"EPI_ISL_18289774\",\"EPI_ISL_18401744\"]\n",
    "df_china_meta['date'] = pd.to_datetime(df_china_meta['Sample_Collection_Date'])\n",
    "df_china_meta1 = df_china_meta[df_china_meta[\"date\"]<=\"2023-08-01\"]\n",
    "df_china_meta2 = df_china_meta1[df_china_meta1[\"date\"]>=\"2023-07-01\"]\n",
    "df_china_meta3 = df_china_meta2[df_china_meta2['province'].isin(['Shanghai', 'Anhui',\"Gansu\"])]\n",
    "element_counts = Counter(df_china_meta3[\"Lineage\"].tolist())\n",
    "element_counts_dict = dict(element_counts)\n",
    "element_counts_dict_sort = dict(sorted(element_counts_dict.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/1/2023 , Anhui , XCN\n",
      "8/1/2023 , Shanghai , XCN\n",
      "8/9/2023 , Anhui , XCN\n",
      "9/3/2023 , Shanghai , XCN\n",
      "9/6/2023 , Anhui , XCN\n",
      "10/6/2023 , Gansu , XCN\n",
      "EPI_ISL_18105656\n",
      "EPI_ISL_18289734\n",
      "EPI_ISL_18289815\n",
      "EPI_ISL_18284946\n",
      "EPI_ISL_18289774\n",
      "EPI_ISL_18401744\n"
     ]
    }
   ],
   "source": [
    "df_china_105 = pd.read_csv(\"/home/soniali/Desktop/02_china_recom_renew/3_recom/meta_105.csv\")\n",
    "epi_meta = []\n",
    "for epi in putative_recom:\n",
    "    df_epi = df_china_105[df_china_105[\"Accession_ID\"] == epi]\n",
    "    print(list(df_epi[\"Sample_Collection_Date\"])[0], \",\",list(df_epi[\"province\"])[0], \",\",list(df_epi[\"Lineage\"])[0])\n",
    "    \n",
    "df =  pd.read_csv(output_file)\n",
    "for i in df.index:\n",
    "    if \"XXXX\" in df.loc[i,\"mutation_pattern\"] and \"YYYY\" in df.loc[i,\"mutation_pattern\"]:\n",
    "        print(df.loc[i,\"sample_id\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Virus_Strain_Name</th>\n",
       "      <th>Accession_ID</th>\n",
       "      <th>Lineage</th>\n",
       "      <th>Sample_Collection_Date</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>merged_lineage</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hCoV-19/Henan/HBCDC-CX109/2023</td>\n",
       "      <td>EPI_ISL_18543055</td>\n",
       "      <td>HK.27.1</td>\n",
       "      <td>10/26/2023</td>\n",
       "      <td>China</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Hebi</td>\n",
       "      <td>EG.5.1*</td>\n",
       "      <td>2023-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hCoV-19/Henan/HBCDC-CX108/2023</td>\n",
       "      <td>EPI_ISL_18543054</td>\n",
       "      <td>HK.2</td>\n",
       "      <td>10/26/2023</td>\n",
       "      <td>China</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Hebi</td>\n",
       "      <td>EG.5.1*</td>\n",
       "      <td>2023-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hCoV-19/Henan/HBCDC-CX106/2023</td>\n",
       "      <td>EPI_ISL_18543053</td>\n",
       "      <td>HK.3</td>\n",
       "      <td>10/26/2023</td>\n",
       "      <td>China</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Hebi</td>\n",
       "      <td>EG.5.1*</td>\n",
       "      <td>2023-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hCoV-19/Henan/HBCDC-CX105/2023</td>\n",
       "      <td>EPI_ISL_18543052</td>\n",
       "      <td>HK.3.2</td>\n",
       "      <td>10/26/2023</td>\n",
       "      <td>China</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Hebi</td>\n",
       "      <td>EG.5.1*</td>\n",
       "      <td>2023-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hCoV-19/Henan/HBCDC-CX104/2023</td>\n",
       "      <td>EPI_ISL_18543051</td>\n",
       "      <td>HK.3</td>\n",
       "      <td>10/26/2023</td>\n",
       "      <td>China</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Hebi</td>\n",
       "      <td>EG.5.1*</td>\n",
       "      <td>2023-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39451</th>\n",
       "      <td>SARS-CoV-2/human/Beijing/3090/2022</td>\n",
       "      <td>EPI_ISL_16350952</td>\n",
       "      <td>DY.2</td>\n",
       "      <td>12/1/2022</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA.5.2.48*</td>\n",
       "      <td>2022-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39452</th>\n",
       "      <td>SARS-CoV-2/human/Beijing/3089/2022</td>\n",
       "      <td>EPI_ISL_16350949</td>\n",
       "      <td>BF.7.14</td>\n",
       "      <td>12/1/2022</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BF.7.14*</td>\n",
       "      <td>2022-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39453</th>\n",
       "      <td>SARS-CoV-2/human/Beijing/3088/2022</td>\n",
       "      <td>EPI_ISL_16350948</td>\n",
       "      <td>DY.2</td>\n",
       "      <td>12/1/2022</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA.5.2.48*</td>\n",
       "      <td>2022-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39454</th>\n",
       "      <td>SARS-CoV-2/human/Beijing/3087/2022</td>\n",
       "      <td>EPI_ISL_16350947</td>\n",
       "      <td>DY.2</td>\n",
       "      <td>12/1/2022</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA.5.2.48*</td>\n",
       "      <td>2022-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39455</th>\n",
       "      <td>SARS-CoV-2/human/Beijing/3086/2022</td>\n",
       "      <td>EPI_ISL_16350946</td>\n",
       "      <td>DY.2</td>\n",
       "      <td>12/1/2022</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA.5.2.48*</td>\n",
       "      <td>2022-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39351 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Virus_Strain_Name      Accession_ID  Lineage   \n",
       "0          hCoV-19/Henan/HBCDC-CX109/2023  EPI_ISL_18543055  HK.27.1  \\\n",
       "1          hCoV-19/Henan/HBCDC-CX108/2023  EPI_ISL_18543054     HK.2   \n",
       "2          hCoV-19/Henan/HBCDC-CX106/2023  EPI_ISL_18543053     HK.3   \n",
       "3          hCoV-19/Henan/HBCDC-CX105/2023  EPI_ISL_18543052   HK.3.2   \n",
       "4          hCoV-19/Henan/HBCDC-CX104/2023  EPI_ISL_18543051     HK.3   \n",
       "...                                   ...               ...      ...   \n",
       "39451  SARS-CoV-2/human/Beijing/3090/2022  EPI_ISL_16350952     DY.2   \n",
       "39452  SARS-CoV-2/human/Beijing/3089/2022  EPI_ISL_16350949  BF.7.14   \n",
       "39453  SARS-CoV-2/human/Beijing/3088/2022  EPI_ISL_16350948     DY.2   \n",
       "39454  SARS-CoV-2/human/Beijing/3087/2022  EPI_ISL_16350947     DY.2   \n",
       "39455  SARS-CoV-2/human/Beijing/3086/2022  EPI_ISL_16350946     DY.2   \n",
       "\n",
       "      Sample_Collection_Date country province  city merged_lineage       date  \n",
       "0                 10/26/2023   China    Henan  Hebi        EG.5.1* 2023-10-26  \n",
       "1                 10/26/2023   China    Henan  Hebi        EG.5.1* 2023-10-26  \n",
       "2                 10/26/2023   China    Henan  Hebi        EG.5.1* 2023-10-26  \n",
       "3                 10/26/2023   China    Henan  Hebi        EG.5.1* 2023-10-26  \n",
       "4                 10/26/2023   China    Henan  Hebi        EG.5.1* 2023-10-26  \n",
       "...                      ...     ...      ...   ...            ...        ...  \n",
       "39451              12/1/2022   China  Beijing   NaN     BA.5.2.48* 2022-12-01  \n",
       "39452              12/1/2022   China  Beijing   NaN       BF.7.14* 2022-12-01  \n",
       "39453              12/1/2022   China  Beijing   NaN     BA.5.2.48* 2022-12-01  \n",
       "39454              12/1/2022   China  Beijing   NaN     BA.5.2.48* 2022-12-01  \n",
       "39455              12/1/2022   China  Beijing   NaN     BA.5.2.48* 2022-12-01  \n",
       "\n",
       "[39351 rows x 9 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_china_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_china_meta['date'] = pd.to_datetime(df_china_meta['Sample_Collection_Date']) \n",
    "df_china_meta = df_china_meta.sort_values(by='date')\n",
    "\n",
    "df_china_meta1 = df_china_meta[df_china_meta[\"date\"]<=\"2023-08-01\"]\n",
    "df_china_meta2 = df_china_meta1[df_china_meta1[\"date\"]>=\"2023-07-01\"]\n",
    "df_china_meta3 = df_china_meta2[df_china_meta2['province'].isin(['Shanghai', 'Anhui',\"Gansu\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EG511 = df_china_meta3[df_china_meta3[\"Lineage\"] == \"EG.5.1.1\"]\n",
    "df_EG511_anhui = df_EG511[df_EG511[\"province\"] == \"Anhui\"] #EPI_ISL_18289730\n",
    "df_EG511_sh = df_EG511[df_EG511[\"province\"] == \"Shanghai\"] #EPI_ISL_18105651 *\n",
    "df_EG511_gansu = df_EG511[df_EG511[\"province\"] == \"Gansu\"] #EPI_ISL_18114672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EPI_ISL_18105651'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EG_list = df_EG511_sh[df_EG511_sh['date'] == '2023-08-01'][\"Accession_ID\"].tolist()\n",
    "import random\n",
    "random.choice(EG_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FR11 = df_china_meta3[df_china_meta3[\"Lineage\"] == \"FR.1.1\"]\n",
    "df_FR11_anhui = df_FR11[df_FR11[\"province\"] == \"Anhui\"] #\n",
    "df_FR11_sh = df_FR11[df_FR11[\"province\"] == \"Shanghai\"] #EPI_ISL_18108456 *\n",
    "df_FR11_gansu = df_FR11[df_FR11[\"province\"] == \"Gansu\"] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EPI_ISL_18108456']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FR_list = df_FR11_sh[df_FR11_sh['date'] == '2023-07-30'][\"Accession_ID\"].tolist()\n",
    "FR_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom_file = \"/home/soniali/Desktop/02_china_recom_renew/3_recom/FR.1.1_XCN_EG.5.1.1.fasta\"\n",
    "with open(\"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/populations.fasta\",\"r\") as f:\n",
    "    for record in SeqIO.parse(f,\"fasta\"):\n",
    "        if record.id in [\"EPI_ISL_18114672\",\"EPI_ISL_18105651\",\"EPI_ISL_18401744\",\"EPI_ISL_18289815\",\"EPI_ISL_18289774\",\"EPI_ISL_18284946\",\"EPI_ISL_18105656\",\"EPI_ISL_18289734\",\"EPI_ISL_18105577\",\"EPI_ISL_18074780\"]:\n",
    "            with open(recom_file,\"a+\") as h:\n",
    "                h.write(\">\"+str(record.id)+\"\\n\")\n",
    "                h.write(str(record.seq)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/soniali/Desktop/02_china_recom_renew/3_recom/reference.fasta\",\"r\") as f:\n",
    "    for record in SeqIO.parse(f,\"fasta\"):\n",
    "        with open(recom_file,\"a+\") as h:\n",
    "            h.write(\">Reference\"+\"\\n\")\n",
    "            h.write(str(record.seq)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"/home/soniali/Desktop/02_china_recom_renew/3_recom/snipit/FR.1.1_XCN_EG.5.1.1_3seqs.fasta\"\n",
    "temp_file = \"/home/soniali/Desktop/02_china_recom_renew/3_recom/snipit/FR.1.1_EG.5.1.1\"\n",
    "#### left\n",
    "with open(infile, \"r\") as f:\n",
    "    for record in SeqIO.parse(f, \"fasta\"):\n",
    "        ID_name = str(record.id)\n",
    "        seq = str(record.seq)\n",
    "        seq_masked = \"\"\n",
    "        for i in range(0,len(seq)):\n",
    "            if i+1 > 22629:\n",
    "                seq_masked = seq_masked+\"N\"\n",
    "            elif i+1 <= 22629:\n",
    "                seq_masked = seq_masked+seq[i:i+1]\n",
    "        \n",
    "        with open(temp_file+\"_masked_left.fasta\", \"a+\") as h:\n",
    "            h.write(\">\"+ID_name+\"\\n\")\n",
    "            h.write(seq_masked+\"\\n\")\n",
    "\n",
    "#### right\n",
    "with open(infile, \"r\") as f:\n",
    "    for record in SeqIO.parse(f, \"fasta\"):\n",
    "        ID_name = str(record.id)\n",
    "        seq = str(record.seq)\n",
    "        seq_masked = \"\"\n",
    "        for i in range(0,len(seq)):\n",
    "            if i+1 < 22664:\n",
    "                seq_masked = seq_masked+\"N\"\n",
    "            elif i+1 >= 22664:\n",
    "                seq_masked = seq_masked+seq[i:i+1]\n",
    "        \n",
    "        with open(temp_file+\"_masked_right.fasta\", \"a+\") as h:\n",
    "            h.write(\">\"+ID_name+\"\\n\")\n",
    "            h.write(seq_masked+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建树\n",
    "# cd /home/soniali/Desktop/02_china_recom_renew/3_recom/snipit/left/\n",
    "# iqtree -s FR.1.1_EG.5.1.1_masked_left.fasta -bb 1000 -alrt 1000 -o Reference\n",
    "\n",
    "# cd /home/soniali/Desktop/02_china_recom_renew/3_recom/snipit/right/\n",
    "# iqtree -s FR.1.1_EG.5.1.1_masked_right.fasta -bb 1000 -alrt 1000 -o Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行Rebar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and run Rebar to detect recombinations in dataset with 39,456 chinese sequences\n",
    "# https://github.com/phac-nml/rebar\n",
    "\n",
    "# conda install -c bioconda rebar\n",
    "# rebar dataset download --name sars-cov-2 --tag 2023-11-30 --output-dir dataset/sars-cov-2/2023-11-30\n",
    "# rebar run --dataset-dir dataset/sars-cov-2/2023-11-30  --populations \"AY.4.2*,BA.5.2,XBC.1.6*,XBB.1.5.1,XBL\" --output-dir output/sars-cov-2\n",
    "# rebar plot --run-dir output/sars-cov-2 --annotations dataset/sars-cov-2/2023-11-30/annotations.tsv\n",
    "\n",
    "# 将dataset/sars-cov-2/2023-11-30/文件夹里的reference.fasta复制至/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/地址\n",
    "# 将/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/nextclade.aligned.fasta更名为 populations.fasta\n",
    "\n",
    "# rebar run --dataset-dir /home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/ --populations \"*\" --output-dir output/China_SARS-CoV-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soniali@soniali-B550M-AORUS-PRO-P:~/Desktop/02_china_recom_renew/3_recom/rebar$ rebar run --dataset-dir /home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/ --populations \"*\" --output-dir output/China_SARS-CoV-2\n",
    "# [INFO  rebar::run] Creating output directory: \"output/China_SARS-CoV-2\"\n",
    "# [INFO  rebar::run] Number of threads available: 24\n",
    "# [INFO  rebar::run] Using 1 thread(s).\n",
    "# [INFO  rebar::dataset::load] Loading dataset: \"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/\"\n",
    "# [WARN  rebar::dataset::load] No summary was found: \"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/summary.json\"\n",
    "# [WARN  rebar::dataset::load] No edge cases were found: \"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/edge_cases.json\"\n",
    "# [WARN  rebar::dataset::load] No phylogeny was found: \"/home/soniali/Desktop/02_china_recom_renew/0_raw_data/GISAID_nextclade/phylogeny.json\"\n",
    "# [INFO  rebar::run] Parsing input populations: [\"*\"]\n",
    "# [INFO  rebar::run] Running recombination search.\n",
    "# ████████████████████████████████████████ 39456/39456 (100%) | Sequences / Second: 7.7435/s | Elapsed: 01:24:55 | ETA: 00:00:00[INFO  rebar::run] Exporting CLI Run Args: \"output/China_SARS-CoV-2/run_args.json\"\n",
    "# [INFO  rebar::run] Exporting linelist: \"output/China_SARS-CoV-2/linelist.tsv\"\n",
    "# [WARN  rebar::run] No recombination detected, no barcodes will be outputted.\n",
    "# [INFO  rebar::run] Done."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90e8717b28a9aac3b69b4bcb0692af4b61da6a939a8351c80ea2b4525614cf09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Mafft': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
